{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import dill as pickle\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "pd.options.display.max_colwidth = 200\n",
    "pd.options.display.max_rows = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collapse data on a per-user basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5523173, 34), (813809, 34), (804310, 34))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn = pd.read_pickle('data/trn.pkl')\n",
    "dev = pd.read_pickle('data/dev.pkl')\n",
    "test = pd.read_pickle('data/test.pkl')\n",
    "\n",
    "trn.shape, dev.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select categorical variables\n",
    "cat_vars = ['track', 'user', 'countries', 'client', 'session', 'format', 'token_w_l2', 'part_of_speech', 'dependency_label'] + [col for col in trn if col.startswith('morphological_features')]\n",
    "len(cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select continuous variables\n",
    "cont_vars = ['days', 'dependency_edge_head', 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine\n",
    "cols = cat_vars + cont_vars + ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert labels to string (to work with padding below)\n",
    "trn['label'] = trn['label'].astype(int).astype(str)\n",
    "dev['label'] = dev['label'].astype(int).astype(str)\n",
    "test['label'] = test['label'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine train and dev sets (used to later train the final model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collapse_to_list(df, cols):\n",
    "    return df[cols].groupby('user').apply(lambda grp: pd.Series({col: grp[col].tolist() for col in grp}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6447, 31), (6437, 31), (6439, 31))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_collapsed = collapse_to_list(trn, cols)\n",
    "dev_collapsed = collapse_to_list(dev, cols)\n",
    "test_collapsed = collapse_to_list(test, cols)\n",
    "\n",
    "trn_collapsed.shape, dev_collapsed.shape, test_collapsed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "trn_collapsed.to_pickle('data/trn_collapsed.pkl')\n",
    "dev_collapsed.to_pickle('data/dev_collapsed.pkl')\n",
    "test_collapsed.to_pickle('data/test_collapsed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create universal mappers to map categorical values from strings and indices\n",
    "UNK = '_unk_'\n",
    "PAD = '_pad_'\n",
    "\n",
    "def create_mapper(toks, max_vocab=100000, min_freq=1, UNK=UNK, PAD=PAD):\n",
    "    \"\"\"Create mappers between tokens and numerical indices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    toks : A list containing all raw tokens.\n",
    "\n",
    "    max_vocab : The maximum vocabulary size.\n",
    "\n",
    "    min_freq : The minimum frequency for a token to be included in the vocabulary.\n",
    "\n",
    "    UNK : Special token for unknown word (default to '_unk_').\n",
    "\n",
    "    PAD : Special token for paddings (default to '_pad_').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stoi : A dictionary that maps tokens to indices.\n",
    "\n",
    "    itos : A list that maps indices to tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    toks_freq = Counter(toks)\n",
    "    \n",
    "    itos = [s for s, c in toks_freq.most_common(max_vocab) if c > min_freq]\n",
    "    \n",
    "    if PAD:\n",
    "        if UNK:\n",
    "            itos.insert(0, UNK)\n",
    "            itos.insert(0, PAD)  # Note the index for UNK is 1 and the index for PAD is 0\n",
    "\n",
    "            stoi = defaultdict(lambda: 1, {v: k for k, v in enumerate(itos)})\n",
    "        else:\n",
    "            itos.insert(0, PAD)  # Note the index for PAD is 0\n",
    "            stoi = {v: k for k, v in enumerate(itos)}\n",
    "    else:\n",
    "        if UNK:\n",
    "            itos.insert(0, UNK)  # Note the index for UNK is 0\n",
    "            stoi = defaultdict(lambda: 0, {v: k for k, v in enumerate(itos)})\n",
    "        else:\n",
    "            stoi = {v: k for k, v in enumerate(itos)}\n",
    "    \n",
    "    return stoi, itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create mappers for each categorical variable using the training data\n",
    "cat_mappers = {}\n",
    "\n",
    "for var in cat_vars + ['label']:\n",
    "    if var == 'token_w_l2':\n",
    "        min_freq = 2\n",
    "    else:\n",
    "        min_freq = 1\n",
    "    \n",
    "    if var == 'label':\n",
    "        UNK = None\n",
    "    else:\n",
    "        UNK = UNK\n",
    "    \n",
    "    cat_mappers[var] = {}\n",
    "    cat_mappers[var]['stoi'], cat_mappers[var]['itos'] = create_mapper(trn[var].tolist(), min_freq=min_freq, UNK=UNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client': 5,\n",
       " 'countries': 128,\n",
       " 'dependency_label': 43,\n",
       " 'format': 5,\n",
       " 'label': 3,\n",
       " 'morphological_features_case': 8,\n",
       " 'morphological_features_definite': 5,\n",
       " 'morphological_features_degree': 7,\n",
       " 'morphological_features_foreign': 4,\n",
       " 'morphological_features_fpos': 65,\n",
       " 'morphological_features_gender': 6,\n",
       " 'morphological_features_mood': 7,\n",
       " 'morphological_features_number': 5,\n",
       " 'morphological_features_numtype': 6,\n",
       " 'morphological_features_person': 6,\n",
       " 'morphological_features_polite': 4,\n",
       " 'morphological_features_poss': 4,\n",
       " 'morphological_features_prepcase': 5,\n",
       " 'morphological_features_prontype': 12,\n",
       " 'morphological_features_reflex': 4,\n",
       " 'morphological_features_tense': 7,\n",
       " 'morphological_features_verbform': 7,\n",
       " 'morphological_features_voice': 4,\n",
       " 'part_of_speech': 18,\n",
       " 'session': 5,\n",
       " 'token_w_l2': 5240,\n",
       " 'track': 5,\n",
       " 'user': 6449}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the vocabulary size for each variable\n",
    "{var: len(cat_mappers[var]['itos']) for var in cat_mappers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8894, 1288, 1284)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the maximum sequence length\n",
    "trn['user'].value_counts().max(), dev['user'].value_counts().max(), test['user'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      64.0\n",
       "0.1     357.0\n",
       "0.2     441.0\n",
       "0.3     510.0\n",
       "0.4     588.0\n",
       "0.5     679.0\n",
       "0.6     782.0\n",
       "0.7     919.0\n",
       "0.8    1131.0\n",
       "0.9    1551.0\n",
       "Name: user, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn['user'].value_counts().quantile(np.arange(0, 1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = dev['user'].value_counts().max()\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode all categorical variables\n",
    "def encode_cat_var(seqs, stoi, max_len, padding_pos='pre', truncating='pre', padding_token=PAD):\n",
    "    # Index\n",
    "    ixs = [[stoi[str_val] for str_val in seq] for seq in seqs]\n",
    "    \n",
    "    # Pad\n",
    "    ixs = pad_sequences(ixs, max_len, padding=padding_pos, truncating=truncating, value=stoi[padding_token])\n",
    "    \n",
    "    return ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_ix_trn = {var: encode_cat_var(trn_collapsed[var], cat_mappers[var]['stoi'], max_len) for var in cat_vars}\n",
    "cat_ix_dev = {var: encode_cat_var(dev_collapsed[var], cat_mappers[var]['stoi'], max_len) for var in cat_vars}\n",
    "cat_ix_test = {var: encode_cat_var(test_collapsed[var], cat_mappers[var]['stoi'], max_len) for var in cat_vars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sanity check encodings\n",
    "def sanity_check_encodings(original_df, cat_ix, cat_vars=cat_vars, cat_mappers=cat_mappers, seed=0, last_n=5):\n",
    "    # Randomly select an observation\n",
    "    np.random.seed(seed)\n",
    "    ix = np.random.choice(np.arange(len(original_df)), 1)[0]\n",
    "    \n",
    "    # Print out both the original and encoded variables\n",
    "    for var in cat_vars:\n",
    "        print('Variable {}:'.format(var))\n",
    "        print('\\tOriginal last {} values:\\t{}'.format(last_n, original_df[var].values[ix][-last_n:]))\n",
    "        print('\\tEncoded last {} values:\\t{}'.format(last_n, [cat_mappers[var]['itos'][i] for i in cat_ix[var][ix][-last_n:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sanity_check_encodings(trn_collapsed, cat_ix_trn)\n",
    "sanity_check_encodings(dev_collapsed, cat_ix_dev)\n",
    "sanity_check_encodings(test_collapsed, cat_ix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode all continuous variables\n",
    "def encode_cont_var(seqs, max_len, padding_pos='pre', truncating='pre', padding_value=-1):\n",
    "    # Pad with -1 (because all these variables are positive)\n",
    "    ixs = pad_sequences(seqs, max_len, padding=padding_pos, truncating=truncating, value=padding_value, dtype='float')\n",
    "    return ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_trn = {var: encode_cont_var(trn_collapsed[var], max_len) for var in cont_vars}\n",
    "cont_dev = {var: encode_cont_var(dev_collapsed[var], max_len) for var in cont_vars}\n",
    "cont_test = {var: encode_cont_var(test_collapsed[var], max_len) for var in cont_vars}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_trn = encode_cat_var(trn_collapsed['label'], cat_mappers['label']['stoi'], max_len)\n",
    "y_dev = encode_cat_var(dev_collapsed['label'], cat_mappers['label']['stoi'], max_len)\n",
    "y_test = encode_cat_var(test_collapsed['label'], cat_mappers['label']['stoi'], max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6447, 1288, 3), (6437, 1288, 3), (6439, 1288, 3))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode\n",
    "y_trn_oh = to_categorical(y_trn)\n",
    "y_dev_oh = to_categorical(y_dev)\n",
    "y_test_oh = to_categorical(y_test)\n",
    "\n",
    "y_trn_oh.shape, y_dev_oh.shape, y_test_oh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats = {\n",
    "    # Categorical features\n",
    "    'cat_ix_trn': cat_ix_trn,\n",
    "    'cat_ix_dev': cat_ix_dev,\n",
    "    'cat_ix_test': cat_ix_test,\n",
    "    \n",
    "    # Numerical features\n",
    "    'cont_trn': cont_trn,\n",
    "    'cont_dev': cont_dev,\n",
    "    'cont_test': cont_test,\n",
    "    \n",
    "    # Labels\n",
    "    'y_trn_oh': y_trn_oh,\n",
    "    'y_dev_oh': y_dev_oh,\n",
    "    'y_test_oh': y_test_oh,\n",
    "    \n",
    "    # Supporting data\n",
    "    'cat_vars': cat_vars,\n",
    "    'cont_vars': cont_vars,\n",
    "    'cat_mappers': cat_mappers,\n",
    "    'max_len': max_len\n",
    "}\n",
    "\n",
    "pickle.dump(feats, open('data/feats.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (General DS)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
